{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ec18b48870846e6",
   "metadata": {},
   "source": [
    "# Amazon Sales Dataset Recommendation System using Collaborative Filtering and Autoencoders\n",
    "\n",
    "**Group members:**\n",
    "- Tasneem Shaheen, 107279\n",
    "- Mostafa Khalid 106699\n",
    "- Medhansh Ahuja 105982\n",
    "\n",
    "The aim for this project is to Build a recommender system to predict user ratings and recommend top products using two approaches: Collaborative Filtering (CF) and Autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d331323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Surprise library version: 1.1.4\n",
      "Starting data preprocessing...\n",
      "Dataset shape after dropping missing values: (1464, 16)\n",
      "Dataset shape after splitting user_id: (11495, 16)\n",
      "Found 1622 duplicate user-item interactions.\n",
      "Dataset shape after aggregating duplicates: (10596, 6)\n",
      "Dataset shape: (10596, 6)\n",
      "Number of unique products: 1350\n",
      "Number of unique users: 9042\n",
      "Sparse matrix shape: (9042, 1350), non-zero entries: 10596\n",
      "Training SVD model...\n",
      "Best SVD RMSE: 0.1346\n",
      "Best SVD Parameters: {'n_factors': 50, 'lr_all': 0.01, 'reg_all': 0.02}\n",
      "Training kNN model...\n",
      "Evaluating kNN with k=10, sim_options={'name': 'cosine', 'user_based': True}\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2755\n",
      "Evaluating kNN with k=10, sim_options={'name': 'pearson', 'user_based': True}\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2864\n",
      "Evaluating kNN with k=20, sim_options={'name': 'cosine', 'user_based': True}\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2759\n",
      "Evaluating kNN with k=20, sim_options={'name': 'pearson', 'user_based': True}\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2865\n",
      "Evaluating kNN with k=40, sim_options={'name': 'cosine', 'user_based': True}\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2753\n",
      "Evaluating kNN with k=40, sim_options={'name': 'pearson', 'user_based': True}\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Mean RMSE: 0.2865\n",
      "Best kNN RMSE: 0.2753\n",
      "Best kNN Parameters: {'k': 40, 'sim_options': {'name': 'cosine', 'user_based': True}}\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Training Autoencoder model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-16 07:22:06.940755: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder Mean RMSE (5-fold CV): 0.1155\n",
      "Evaluating models...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "SVD Test RMSE: 0.13065526873700165\n",
      "SVD Precision@10: 0.7345588235294118\n",
      "SVD Recall@10: 0.7352941176470589\n",
      "kNN Test RMSE: 0.27625971386341736\n",
      "kNN Precision@10: 0.7345588235294118\n",
      "kNN Recall@10: 0.7352941176470589\n",
      "Autoencoder Test RMSE: 0.1135829801247042\n",
      "Autoencoder Precision@10: 0.7345588235294118\n",
      "Autoencoder Recall@10: 0.7352941176470589\n",
      "\n",
      "Chart.js Configuration for Model Comparison:\n",
      "{\n",
      "  \"type\": \"bar\",\n",
      "  \"data\": {\n",
      "    \"labels\": [\n",
      "      \"SVD\",\n",
      "      \"kNN\",\n",
      "      \"Autoencoder\"\n",
      "    ],\n",
      "    \"datasets\": [\n",
      "      {\n",
      "        \"label\": \"Test RMSE\",\n",
      "        \"data\": [\n",
      "          0.13065526873700165,\n",
      "          0.27625971386341736,\n",
      "          0.1135829801247042\n",
      "        ],\n",
      "        \"backgroundColor\": \"#FF6B6B\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"Precision@10\",\n",
      "        \"data\": [\n",
      "          0.7345588235294118,\n",
      "          0.7345588235294118,\n",
      "          0.7345588235294118\n",
      "        ],\n",
      "        \"backgroundColor\": \"#4ECDC4\"\n",
      "      },\n",
      "      {\n",
      "        \"label\": \"Recall@10\",\n",
      "        \"data\": [\n",
      "          0.7352941176470589,\n",
      "          0.7352941176470589,\n",
      "          0.7352941176470589\n",
      "        ],\n",
      "        \"backgroundColor\": \"#45B7D1\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  \"options\": {\n",
      "    \"scales\": {\n",
      "      \"y\": {\n",
      "        \"beginAtZero\": true,\n",
      "        \"title\": {\n",
      "          \"display\": true,\n",
      "          \"text\": \"Scores\"\n",
      "        }\n",
      "      },\n",
      "      \"x\": {\n",
      "        \"title\": {\n",
      "          \"display\": true,\n",
      "          \"text\": \"Models\"\n",
      "        }\n",
      "      }\n",
      "    },\n",
      "    \"plugins\": {\n",
      "      \"title\": {\n",
      "        \"display\": true,\n",
      "        \"text\": \"Model Comparison: RMSE, Precision@10, Recall@10\"\n",
      "      },\n",
      "      \"legend\": {\n",
      "        \"display\": true\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "Detailed Analysis:\n",
      "- RMSE Difference (SVD vs Autoencoder): 0.0171\n",
      "- Precision@10 Difference (SVD vs Autoencoder): 0.0000\n",
      "- Autoencoder has 0.0% higher Precision@10\n",
      "- Recall@10 Difference (SVD vs Autoencoder): 0.0000\n",
      "- Autoencoder has 0.0% higher Recall@10\n",
      "\n",
      "Metrics saved to results/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Amazon Sales Dataset Recommendation System\n",
    "# Group members: Tasneem Shaheen (107279), Mostafa Khalid (106699), Medhansh Ahuja (105982)\n",
    "# This script builds a recommender system using SVD (baseline), kNN, and Autoencoder.\n",
    "# Evaluates models with 5-fold cross-validation on RMSE, Precision@10, and Recall@10.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import SVD, KNNBasic, Dataset, Reader\n",
    "from surprise.model_selection import cross_validate, train_test_split\n",
    "from surprise.accuracy import rmse\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "import os\n",
    "import surprise\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress CUDA warnings by forcing CPU usage\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''  # Disable GPU\n",
    "\n",
    "# Print library version for debugging\n",
    "print(f\"Surprise library version: {surprise.__version__}\")\n",
    "\n",
    "# 1. Data Preprocessing\n",
    "def preprocess_data(input_file='amazon.csv', output_file='amazon_preprocessed.csv'):\n",
    "    print(\"Starting data preprocessing...\")\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        df = pd.read_csv(input_file)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: {input_file} not found. Please ensure the dataset is in the correct directory.\")\n",
    "        return None, None, None, None, None\n",
    "    \n",
    "    # Handle mixed types\n",
    "    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
    "    df['rating_count'] = df['rating_count'].str.replace(',', '').astype(float, errors='ignore')\n",
    "    \n",
    "    # Drop missing critical fields\n",
    "    df = df.dropna(subset=['user_id', 'product_id', 'rating'])\n",
    "    print(f\"Dataset shape after dropping missing values: {df.shape}\")\n",
    "    \n",
    "    # Split comma-separated user_id into individual rows\n",
    "    df_expanded = df.assign(user_id=df['user_id'].str.split(',')).explode('user_id')\n",
    "    df_expanded = df_expanded.dropna(subset=['user_id'])\n",
    "    print(f\"Dataset shape after splitting user_id: {df_expanded.shape}\")\n",
    "    \n",
    "    # Sentiment analysis on review_content\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    df_expanded['sentiment_score'] = df_expanded['review_content'].apply(\n",
    "        lambda x: analyzer.polarity_scores(str(x))['compound'] if pd.notnull(x) else 0\n",
    "    )\n",
    "    \n",
    "    # Encode user_id and product_id\n",
    "    user_encoder = LabelEncoder()\n",
    "    item_encoder = LabelEncoder()\n",
    "    df_expanded['user_idx'] = user_encoder.fit_transform(df_expanded['user_id'])\n",
    "    df_expanded['item_idx'] = item_encoder.fit_transform(df_expanded['product_id'])\n",
    "    \n",
    "    # Check for duplicate user_idx, item_idx pairs\n",
    "    duplicates = df_expanded.duplicated(subset=['user_idx', 'item_idx'], keep=False)\n",
    "    if duplicates.any():\n",
    "        print(f\"Found {duplicates.sum()} duplicate user-item interactions.\")\n",
    "        # Aggregate duplicates by taking the mean rating\n",
    "        df_expanded = df_expanded.groupby(['user_idx', 'item_idx']).agg({\n",
    "            'rating': 'mean',\n",
    "            'user_id': 'first',\n",
    "            'product_id': 'first',\n",
    "            'sentiment_score': 'mean'\n",
    "        }).reset_index()\n",
    "        print(f\"Dataset shape after aggregating duplicates: {df_expanded.shape}\")\n",
    "    \n",
    "    # Create user-item matrix\n",
    "    try:\n",
    "        pivot_table = df_expanded.pivot(index='user_idx', columns='item_idx', values='rating').fillna(0)\n",
    "    except ValueError as e:\n",
    "        print(f\"Error during pivot: {e}\")\n",
    "        return None, None, None, None, None\n",
    "    sparse_matrix = csr_matrix(pivot_table.values)\n",
    "    \n",
    "    # Save preprocessed dataset\n",
    "    df_expanded.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"Dataset shape: {df_expanded.shape}\")\n",
    "    print(f\"Number of unique products: {df_expanded['product_id'].nunique()}\")\n",
    "    print(f\"Number of unique users: {df_expanded['user_id'].nunique()}\")\n",
    "    print(f\"Sparse matrix shape: {sparse_matrix.shape}, non-zero entries: {sparse_matrix.nnz}\")\n",
    "    \n",
    "    return df_expanded, sparse_matrix, pivot_table, user_encoder, item_encoder\n",
    "\n",
    "# 2. Visualizations\n",
    "def plot_visualizations(df_expanded, pivot_table):\n",
    "    if df_expanded is None or pivot_table is None:\n",
    "        print(\"Skipping visualizations due to preprocessing error.\")\n",
    "        return\n",
    "    \n",
    "    # Create results directory if it doesn't exist\n",
    "    os.makedirs('results', exist_ok=True)\n",
    "    \n",
    "    # Rating distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df_expanded['rating'], bins=10, kde=True)\n",
    "    plt.title('Distribution of Ratings')\n",
    "    plt.xlabel('Rating')\n",
    "    plt.ylabel('Count')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('results/rating_distribution.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # Sparsity visualization (subset for readability)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(pivot_table.iloc[:100, :100], cmap='Blues', cbar_kws={'label': 'Rating'})\n",
    "    plt.title('User-Item Matrix Sparsity (First 100 Users and Items)')\n",
    "    plt.xlabel('Item Index')\n",
    "    plt.ylabel('User Index')\n",
    "    plt.savefig('results/sparsity_heatmap.png')\n",
    "    plt.close()\n",
    "\n",
    "# 3. SVD Model (Baseline)\n",
    "def train_svd(df_expanded):\n",
    "    if df_expanded is None:\n",
    "        print(\"Skipping SVD training due to preprocessing error.\")\n",
    "        return None, None\n",
    "    \n",
    "    print(\"Training SVD model...\")\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(df_expanded[['user_id', 'product_id', 'rating']], reader)\n",
    "    \n",
    "    # 5-fold Cross-Validation\n",
    "    param_grid = {\n",
    "        'n_factors': [50, 100, 200],\n",
    "        'lr_all': [0.005, 0.01],\n",
    "        'reg_all': [0.02, 0.1]\n",
    "    }\n",
    "    gs_svd = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=5)\n",
    "    gs_svd.fit(data)\n",
    "    print(f\"Best SVD RMSE: {gs_svd.best_score['rmse']:.4f}\")\n",
    "    print(f\"Best SVD Parameters: {gs_svd.best_params['rmse']}\")\n",
    "    \n",
    "    # Train final model\n",
    "    svd = SVD(**gs_svd.best_params['rmse'])\n",
    "    trainset = data.build_full_trainset()\n",
    "    svd.fit(trainset)\n",
    "    return svd, data\n",
    "\n",
    "# 4. kNN Model (User-Based)\n",
    "def train_knn(df_expanded):\n",
    "    if df_expanded is None:\n",
    "        print(\"Skipping kNN training due to preprocessing error.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Training kNN model...\")\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    data = Dataset.load_from_df(df_expanded[['user_id', 'product_id', 'rating']], reader)\n",
    "    \n",
    "    # Manual cross-validation to avoid GridSearchCV issues\n",
    "    k_values = [10, 20, 40]\n",
    "    sim_options_list = [\n",
    "        {'name': 'cosine', 'user_based': True},\n",
    "        {'name': 'pearson', 'user_based': True}\n",
    "    ]\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_knn = None\n",
    "    \n",
    "    for k in k_values:\n",
    "        for sim_options in sim_options_list:\n",
    "            print(f\"Evaluating kNN with k={k}, sim_options={sim_options}\")\n",
    "            knn = KNNBasic(k=k, sim_options=sim_options)\n",
    "            cv_results = cross_validate(knn, data, measures=['rmse', 'mae'], cv=5, verbose=False)\n",
    "            mean_rmse = np.mean(cv_results['test_rmse'])\n",
    "            print(f\"Mean RMSE: {mean_rmse:.4f}\")\n",
    "            if mean_rmse < best_rmse:\n",
    "                best_rmse = mean_rmse\n",
    "                best_params = {'k': k, 'sim_options': sim_options}\n",
    "                best_knn = knn\n",
    "    \n",
    "    print(f\"Best kNN RMSE: {best_rmse:.4f}\")\n",
    "    print(f\"Best kNN Parameters: {best_params}\")\n",
    "    \n",
    "    # Train final model\n",
    "    trainset = data.build_full_trainset()\n",
    "    best_knn.fit(trainset)\n",
    "    return best_knn\n",
    "\n",
    "# 5. Autoencoder Model\n",
    "def train_autoencoder(sparse_matrix):\n",
    "    if sparse_matrix is None:\n",
    "        print(\"Skipping Autoencoder training due to preprocessing error.\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Training Autoencoder model...\")\n",
    "    X = sparse_matrix.toarray()\n",
    "    \n",
    "    def build_autoencoder(hidden_units=100, dropout_rate=0.2):\n",
    "        model = Sequential([\n",
    "            Input(shape=(X.shape[1],)),\n",
    "            Dense(hidden_units, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(hidden_units // 2, activation='relu'),\n",
    "            Dense(X.shape[1], activation='linear')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mse')\n",
    "        return model\n",
    "    \n",
    "    # 5-Fold Cross-Validation\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    rmse_scores = []\n",
    "    for train_idx, val_idx in kf.split(X):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        model = build_autoencoder()\n",
    "        model.fit(X_train, X_train, epochs=10, batch_size=32, validation_data=(X_val, X_val), verbose=0)\n",
    "        val_pred = model.predict(X_val, verbose=0)\n",
    "        rmse = np.sqrt(np.mean((X_val - val_pred) ** 2))\n",
    "        rmse_scores.append(rmse)\n",
    "    print(f\"Autoencoder Mean RMSE (5-fold CV): {np.mean(rmse_scores):.4f}\")\n",
    "    \n",
    "    # Train final model\n",
    "    autoencoder = build_autoencoder()\n",
    "    autoencoder.fit(X, X, epochs=10, batch_size=32, verbose=0)\n",
    "    return autoencoder\n",
    "\n",
    "# 6. Evaluation\n",
    "def evaluate_models(svd, knn, autoencoder, data, pivot_table, user_encoder, item_encoder):\n",
    "    if data is None or pivot_table is None:\n",
    "        print(\"Skipping evaluation due to preprocessing error.\")\n",
    "        return [None] * 9\n",
    "    if svd is None or knn is None or autoencoder is None:\n",
    "        print(\"Warning: One or more models failed to train. Evaluating available models.\")\n",
    "    \n",
    "    print(\"Evaluating models...\")\n",
    "    trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # SVD Evaluation\n",
    "    svd_rmse, svd_prec, svd_recall = None, None, None\n",
    "    if svd is not None:\n",
    "        svd.fit(trainset)\n",
    "        svd_predictions = svd.test(testset)\n",
    "        svd_rmse = rmse(svd_predictions, verbose=False)\n",
    "        svd_prec, svd_recall = precision_recall_at_k(svd_predictions)\n",
    "    \n",
    "    # kNN Evaluation\n",
    "    knn_rmse, knn_prec, knn_recall = None, None, None\n",
    "    if knn is not None:\n",
    "        knn.fit(trainset)\n",
    "        knn_predictions = knn.test(testset)\n",
    "        knn_rmse = rmse(knn_predictions, verbose=False)\n",
    "        knn_prec, knn_recall = precision_recall_at_k(knn_predictions)\n",
    "    \n",
    "    # Autoencoder Evaluation\n",
    "    auto_rmse, auto_prec, auto_recall = None, None, None\n",
    "    if autoencoder is not None:\n",
    "        # Map user_id to user_idx\n",
    "        test_indices = []\n",
    "        skipped = 0\n",
    "        for x in testset:\n",
    "            try:\n",
    "                user_idx = user_encoder.transform([x[0]])[0]\n",
    "                test_indices.append(user_idx)\n",
    "            except ValueError:\n",
    "                skipped += 1\n",
    "                continue\n",
    "        if skipped > 0:\n",
    "            print(f\"Warning: Skipped {skipped} testset entries due to unknown user_id.\")\n",
    "        if test_indices:\n",
    "            test_users = pivot_table.iloc[test_indices].values\n",
    "            auto_pred = autoencoder.predict(test_users, verbose=0)\n",
    "            auto_rmse = np.sqrt(np.mean((test_users - auto_pred) ** 2))\n",
    "            auto_prec, auto_recall = autoencoder_precision_recall(autoencoder, pivot_table, testset, user_encoder, item_encoder)\n",
    "        else:\n",
    "            print(\"Warning: No valid test indices for Autoencoder evaluation.\")\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"SVD Test RMSE: {svd_rmse if svd_rmse is not None else 'N/A'}\")\n",
    "    print(f\"SVD Precision@10: {svd_prec if svd_prec is not None else 'N/A'}\")\n",
    "    print(f\"SVD Recall@10: {svd_recall if svd_recall is not None else 'N/A'}\")\n",
    "    print(f\"kNN Test RMSE: {knn_rmse if knn_rmse is not None else 'N/A'}\")\n",
    "    print(f\"kNN Precision@10: {knn_prec if knn_prec is not None else 'N/A'}\")\n",
    "    print(f\"kNN Recall@10: {knn_recall if knn_recall is not None else 'N/A'}\")\n",
    "    print(f\"Autoencoder Test RMSE: {auto_rmse if auto_rmse is not None else 'N/A'}\")\n",
    "    print(f\"Autoencoder Precision@10: {auto_prec if auto_prec is not None else 'N/A'}\")\n",
    "    print(f\"Autoencoder Recall@10: {auto_recall if auto_recall is not None else 'N/A'}\")\n",
    "    \n",
    "    return svd_rmse, svd_prec, svd_recall, knn_rmse, knn_prec, knn_recall, auto_rmse, auto_prec, auto_recall\n",
    "\n",
    "# Precision@10 and Recall@10 for Autoencoder\n",
    "def autoencoder_precision_recall(autoencoder, pivot_table, testset, user_encoder, item_encoder, k=10, threshold=4.0):\n",
    "    test_indices = []\n",
    "    user_item_pairs = []\n",
    "    skipped = 0\n",
    "    for x in testset:\n",
    "        try:\n",
    "            user_idx = user_encoder.transform([x[0]])[0]\n",
    "            test_indices.append(user_idx)\n",
    "            user_item_pairs.append((x[0], x[1], x[2]))  # user_id, item_id, true_rating\n",
    "        except ValueError:\n",
    "            skipped += 1\n",
    "            continue\n",
    "    if skipped > 0:\n",
    "        print(f\"Warning: Skipped {skipped} testset entries due to unknown user_id in Autoencoder precision/recall.\")\n",
    "    if not test_indices:\n",
    "        print(\"Warning: No valid test indices for Autoencoder precision/recall.\")\n",
    "        return 0, 0\n",
    "    \n",
    "    test_users = pivot_table.iloc[test_indices].values\n",
    "    auto_pred = autoencoder.predict(test_users, verbose=0)\n",
    "    user_pred = {}\n",
    "    skipped_items = 0\n",
    "    for idx, (uid, iid, true_r) in enumerate(user_item_pairs):\n",
    "        if uid not in user_pred:\n",
    "            user_pred[uid] = []\n",
    "        try:\n",
    "            item_idx = item_encoder.transform([iid])[0]\n",
    "            est = auto_pred[idx, item_idx]\n",
    "            user_pred[uid].append((est, true_r))\n",
    "        except ValueError:\n",
    "            skipped_items += 1\n",
    "            continue\n",
    "    if skipped_items > 0:\n",
    "        print(f\"Warning: Skipped {skipped_items} testset entries due to unknown item_id.\")\n",
    "    \n",
    "    precision, recall = [], []\n",
    "    for uid, preds in user_pred.items():\n",
    "        preds.sort(reverse=True)\n",
    "        top_k = preds[:k]\n",
    "        n_rel = sum(1 for _, r in top_k if r >= threshold)\n",
    "        n_rec = len(top_k)\n",
    "        n_rel_total = sum(1 for _, r in preds if r >= threshold)\n",
    "        precision.append(n_rel / n_rec if n_rec > 0 else 0)\n",
    "        recall.append(n_rel / n_rel_total if n_rel_total > 0 else 0)\n",
    "    return np.mean(precision) if precision else 0, np.mean(recall) if recall else 0\n",
    "\n",
    "# Precision@10 and Recall@10 for SVD and kNN\n",
    "def precision_recall_at_k(predictions, k=10, threshold=4.0):\n",
    "    user_pred = {}\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        if uid not in user_pred:\n",
    "            user_pred[uid] = []\n",
    "        user_pred[uid].append((est, true_r))\n",
    "    precision, recall = [], []\n",
    "    for uid, preds in user_pred.items():\n",
    "        preds.sort(reverse=True)\n",
    "        top_k = preds[:k]\n",
    "        n_rel = sum(1 for _, r in top_k if r >= threshold)\n",
    "        n_rec = len(top_k)\n",
    "        n_rel_total = sum(1 for _, r in preds if r >= threshold)\n",
    "        precision.append(n_rel / n_rec if n_rec > 0 else 0)\n",
    "        recall.append(n_rel / n_rel_total if n_rel_total > 0 else 0)\n",
    "    return np.mean(precision), np.mean(recall)\n",
    "\n",
    "# 7. Model Comparison\n",
    "def plot_model_comparison(svd_rmse, svd_prec, svd_recall, knn_rmse, knn_prec, knn_recall, auto_rmse, auto_prec, auto_recall):\n",
    "    if all(x is None for x in [svd_rmse, knn_rmse, auto_rmse]):\n",
    "        print(\"Skipping model comparison due to evaluation error.\")\n",
    "        return\n",
    "    \n",
    "    # Chart.js configuration\n",
    "    chart_config = {\n",
    "        \"type\": \"bar\",\n",
    "        \"data\": {\n",
    "            \"labels\": [\"SVD\", \"kNN\", \"Autoencoder\"],\n",
    "            \"datasets\": [\n",
    "                {\n",
    "                    \"label\": \"Test RMSE\",\n",
    "                    \"data\": [\n",
    "                        svd_rmse if svd_rmse is not None else None,\n",
    "                        knn_rmse if knn_rmse is not None else None,\n",
    "                        auto_rmse if auto_rmse is not None else None\n",
    "                    ],\n",
    "                    \"backgroundColor\": \"#FF6B6B\"\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"Precision@10\",\n",
    "                    \"data\": [\n",
    "                        svd_prec if svd_prec is not None else None,\n",
    "                        knn_prec if knn_prec is not None else None,\n",
    "                        auto_prec if auto_prec is not None else None\n",
    "                    ],\n",
    "                    \"backgroundColor\": \"#4ECDC4\"\n",
    "                },\n",
    "                {\n",
    "                    \"label\": \"Recall@10\",\n",
    "                    \"data\": [\n",
    "                        svd_recall if svd_recall is not None else None,\n",
    "                        knn_recall if knn_recall is not None else None,\n",
    "                        auto_recall if auto_recall is not None else None\n",
    "                    ],\n",
    "                    \"backgroundColor\": \"#45B7D1\"\n",
    "                }\n",
    "            ]\n",
    "        },\n",
    "        \"options\": {\n",
    "            \"scales\": {\n",
    "                \"y\": {\"beginAtZero\": True, \"title\": {\"display\": True, \"text\": \"Scores\"}},\n",
    "                \"x\": {\"title\": {\"display\": True, \"text\": \"Models\"}}\n",
    "            },\n",
    "            \"plugins\": {\n",
    "                \"title\": {\"display\": True, \"text\": \"Model Comparison: RMSE, Precision@10, Recall@10\"},\n",
    "                \"legend\": {\"display\": True}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    print(\"\\nChart.js Configuration for Model Comparison:\")\n",
    "    print(json.dumps(chart_config, indent=2))\n",
    "    \n",
    "    # Detailed analysis\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    if svd_rmse is not None and auto_rmse is not None:\n",
    "        print(f\"- RMSE Difference (SVD vs Autoencoder): {abs(svd_rmse - auto_rmse):.4f}\")\n",
    "    if svd_prec is not None and auto_prec is not None and svd_prec > 0 and auto_prec > 0:\n",
    "        print(f\"- Precision@10 Difference (SVD vs Autoencoder): {abs(svd_prec - auto_prec):.4f}\")\n",
    "        if svd_prec > auto_prec:\n",
    "            print(f\"- SVD has {((svd_prec - auto_prec) / auto_prec * 100):.1f}% higher Precision@10\")\n",
    "        else:\n",
    "            print(f\"- Autoencoder has {((auto_prec - svd_prec) / svd_prec * 100):.1f}% higher Precision@10\")\n",
    "    if svd_recall is not None and auto_recall is not None and svd_recall > 0 and auto_recall > 0:\n",
    "        print(f\"- Recall@10 Difference (SVD vs Autoencoder): {abs(svd_recall - auto_recall):.4f}\")\n",
    "        if svd_recall > auto_recall:\n",
    "            print(f\"- SVD has {((svd_recall - auto_recall) / auto_recall * 100):.1f}% higher Recall@10\")\n",
    "        else:\n",
    "            print(f\"- Autoencoder has {((auto_recall - svd_recall) / svd_recall * 100):.1f}% higher Recall@10\")\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Preprocess data\n",
    "    df_expanded, sparse_matrix, pivot_table, user_encoder, item_encoder = preprocess_data()\n",
    "    \n",
    "    # Plot visualizations\n",
    "    plot_visualizations(df_expanded, pivot_table)\n",
    "    \n",
    "    # Train models\n",
    "    svd, data = train_svd(df_expanded)\n",
    "    knn = train_knn(df_expanded)\n",
    "    autoencoder = train_autoencoder(sparse_matrix)\n",
    "    \n",
    "    # Evaluate models\n",
    "    metrics = evaluate_models(svd, knn, autoencoder, data, pivot_table, user_encoder, item_encoder)\n",
    "    svd_rmse, svd_prec, svd_recall, knn_rmse, knn_prec, knn_recall, auto_rmse, auto_prec, auto_recall = metrics\n",
    "    \n",
    "    # Plot model comparison\n",
    "    plot_model_comparison(svd_rmse, svd_prec, svd_recall, knn_rmse, knn_prec, knn_recall, auto_rmse, auto_prec, auto_recall)\n",
    "    \n",
    "    # Save metrics\n",
    "    if any(x is not None for x in metrics):\n",
    "        metrics_df = pd.DataFrame({\n",
    "            'Model': ['SVD', 'kNN', 'Autoencoder'],\n",
    "            'RMSE': [svd_rmse if svd_rmse is not None else 'N/A',\n",
    "                     knn_rmse if knn_rmse is not None else 'N/A',\n",
    "                     auto_rmse if auto_rmse is not None else 'N/A'],\n",
    "            'Precision@10': [svd_prec if svd_prec is not None else 'N/A',\n",
    "                             knn_prec if knn_prec is not None else 'N/A',\n",
    "                             auto_prec if auto_prec is not None else 'N/A'],\n",
    "            'Recall@10': [svd_recall if svd_recall is not None else 'N/A',\n",
    "                          knn_recall if knn_recall is not None else 'N/A',\n",
    "                          auto_recall if auto_recall is not None else 'N/A']\n",
    "        })\n",
    "        os.makedirs('results', exist_ok=True)\n",
    "        metrics_df.to_csv('results/metrics.csv', index=False)\n",
    "        print(\"\\nMetrics saved to results/metrics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
